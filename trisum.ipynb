{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e932dd6-2894-4033-bf82-ff1ffb9f53e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.cpp_extension import load\n",
    "\n",
    "trisum = load(name='trisum_cuda', sources=['trisum_cuda.cpp', 'trisum_cuda_kernel.cu'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25924b0d-81a3-4837-b2be-5439a61663f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2305f31d-09ee-4c95-ab95-3e86fbbeec95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__spec__',\n",
       " 'backward',\n",
       " 'forward']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(trisum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c5b2803-ea01-4c00-afd4-fdfabcd70c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trisumt import trisum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e2599db-a9ed-4dc0-b74e-fa9bfb19911a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sz = 16\n",
    "idxs = torch.arange(sz).repeat(3).reshape(1,3*sz).to(torch.int32)\n",
    "int(idxs[0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa8ca6db-6852-404d-8792-66d60ab85c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "bs = 16*256\n",
    "sz = 256\n",
    "device = torch.device(\"cuda:1\")\n",
    "rnn = trisum(sz).to(device)\n",
    "X =  torch.arange(bs*sz).reshape(bs,sz).to(torch.float32).to(device)\n",
    "idxs = torch.arange(sz).repeat(3*sz).reshape(1,3*sz**2).to(torch.int32).to(device)\n",
    "idxs = torch.cat([idxs,torch.flip(idxs,[1])],dim = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3dc4c3e-7e41-4615-8236-7c1fbbccc518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -55.1102,    1.3186, -289.5669,  ...,  -91.2199,  112.6162,\n",
      "          -24.7189],\n",
      "        [ -55.1102,    1.3186, -289.5669,  ...,  -91.2199,  112.6162,\n",
      "          -24.7189],\n",
      "        [ -55.1102,    1.3186, -289.5669,  ...,  -91.2199,  112.6162,\n",
      "          -24.7189],\n",
      "        ...,\n",
      "        [ -55.1102,    1.3186, -289.5669,  ...,  -91.2199,  112.6162,\n",
      "          -24.7189],\n",
      "        [ -55.1102,    1.3186, -289.5669,  ...,  -91.2199,  112.6162,\n",
      "          -24.7189],\n",
      "        [ -55.1102,    1.3186, -289.5669,  ...,  -91.2199,  112.6162,\n",
      "          -24.7189]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "#print(idxs.shape)\n",
    "#print(idxs[0,0:5],idxs[1,0:5])\n",
    "for _ in range(100):\n",
    "    output = rnn(X,idxs,idxs)\n",
    "print(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46731b05-b0c1-430b-8101-728cdae1a476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -55.1102,    1.3187, -289.5668,  ...,  -91.2201,  112.6162,\n",
      "          -24.7189],\n",
      "        [ -55.1102,    1.3187, -289.5668,  ...,  -91.2201,  112.6162,\n",
      "          -24.7189],\n",
      "        [ -55.1102,    1.3187, -289.5668,  ...,  -91.2201,  112.6162,\n",
      "          -24.7189],\n",
      "        ...,\n",
      "        [ -55.1102,    1.3187, -289.5668,  ...,  -91.2201,  112.6162,\n",
      "          -24.7189],\n",
      "        [ -55.1102,    1.3187, -289.5668,  ...,  -91.2201,  112.6162,\n",
      "          -24.7189],\n",
      "        [ -55.1102,    1.3187, -289.5668,  ...,  -91.2201,  112.6162,\n",
      "          -24.7189]], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "idxs2 = idxs.clone().to(torch.long)\n",
    "for _ in range(100):\n",
    "    y = X[:,idxs2[0]] - X[:,idxs2[1]]\n",
    "    #indexing to maintain Rotation and Translation invariance, Break Mirror invariance\n",
    "    weights = rnn.weights.data\n",
    "    y = (y*weights.view(1,3*sz**2)).reshape((bs, sz, sz,3)).sum(-1).sum(-1)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e4e26d19-154d-4b75-b7b5-4ab077152888",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0478,  0.0519, -0.0146,  ...,  0.0031,  0.0192, -0.0023],\n",
       "       device='cuda:1')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnn.weights.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a99ba2fd-404c-47d3-9015-8890448c8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Custom backward pass check\n",
    "import math\n",
    "\n",
    "class TriangSum(nn.Module):\n",
    "    def __init__(self,  state_size):\n",
    "        super(TriangSum, self).__init__()\n",
    "\n",
    "        self.state_size = state_size\n",
    "        self.weights = nn.Parameter(torch.Tensor(3*state_size**2))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.state_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, +stdv)\n",
    "\n",
    "    def forward(self, x, idxs):\n",
    "        y = x[:,idxs[0]] - x[:,idxs[1]]\n",
    "        weights = rnn.weights.data\n",
    "        y = (y*self.weights.view(1,3*sz**2)).reshape((bs, sz, sz,3)).sum(-1).sum(-1)\n",
    "        \n",
    "        return y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb42cf15-7719-4e40-af4f-a6d7a4a5fbd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47916/3546125513.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X =  torch.tensor(torch.arange(bs*sz).reshape(bs,sz).to(torch.float32).to(device), requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "bs = 16*256\n",
    "sz = 256\n",
    "device = torch.device(\"cuda:1\")\n",
    "rnn = trisum(sz).to(device)\n",
    "X =  torch.tensor(torch.arange(bs*sz).reshape(bs,sz).to(torch.float32).to(device), requires_grad=True)\n",
    "idxs = torch.arange(sz).repeat(3*sz).reshape(1,3*sz**2).to(torch.int32).to(device)\n",
    "idxs = torch.cat([idxs,torch.flip(idxs,[1])],dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3d0627a4-65dc-4cfa-8f12-8e086691f2ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.grad tensor([[ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        ...,\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409]],\n",
      "       device='cuda:1')\n",
      "weights.grad tensor([-1044480., -1036288., -1028096.,  ...,  1028096.,  1036288.,\n",
      "         1044480.], device='cuda:1')\n",
      "X.grad shape torch.Size([4096, 256])\n",
      "weights.grad shape  torch.Size([196608])\n"
     ]
    }
   ],
   "source": [
    "TriaSum = TriangSum(sz).to(device)\n",
    "idxs2 = idxs.clone().to(torch.long)\n",
    "Q = TriaSum(X, idxs2)\n",
    "external_grad = torch.ones(Q.shape).to(device)\n",
    "#external_grad = torch.rand(Q.shape).to(device)\n",
    "Q.backward(gradient=external_grad)\n",
    "print(\"X.grad\", X.grad)\n",
    "print(\"weights.grad\", TriaSum.weights.grad)\n",
    "print(\"X.grad shape\", X.grad.shape)\n",
    "print(\"weights.grad shape \", TriaSum.weights.grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "36bdf805-8423-4acc-aa00-1c3261decbe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 196608])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "80e57281-568b-4028-96bc-badea0a1de29",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47916/3070663716.py:41: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return torch.tensor(idxs_bw).to(torch.int32)\n"
     ]
    }
   ],
   "source": [
    "def make_idxs_backward(idxs, num_patches):\n",
    "    dim = 3*num_patches**2\n",
    "    idxs_bw = torch.zeros((4,dim)).to(torch.long)\n",
    "    ct = 0\n",
    "    ct2 = 0\n",
    "    for i in range(num_patches):\n",
    "        for j in range(dim):\n",
    "            if idxs[0][j] == i:\n",
    "                c = j//(3*num_patches)\n",
    "                idxs_bw[0][ct] = c\n",
    "                idxs_bw[2][ct] = j \n",
    "                ct+=1\n",
    "            if idxs[1][j] == i:\n",
    "                c = j//(3*num_patches)\n",
    "                idxs_bw[1][ct2] = c\n",
    "                idxs_bw[3][ct2] = j \n",
    "                ct2+=1\n",
    "    return torch.tensor(idxs_bw).to(torch.int32)\n",
    "\n",
    "\n",
    "def make_idxs_backward2(idxs, num_patches):\n",
    "    dim = 3*num_patches**2\n",
    "    idxs_bw = torch.zeros((4,dim)).to(torch.long)\n",
    "    ct = 0\n",
    "    ct2 = 0\n",
    "    for i in range(num_patches):\n",
    "        idx = (idxs[0] == i).nonzero(as_tuple=True)[0].tolist()\n",
    "        for j in idx:\n",
    "            if idxs[0][j] == i:\n",
    "                c = j//(3*num_patches)\n",
    "                idxs_bw[0][ct] = c\n",
    "                idxs_bw[2][ct] = j \n",
    "                ct+=1\n",
    "        idx = (idxs[1] == i).nonzero(as_tuple=True)[0].tolist()\n",
    "        for j in idx:\n",
    "            if idxs[1][j] == i:\n",
    "                c = j//(3*num_patches)\n",
    "                idxs_bw[1][ct2] = c\n",
    "                idxs_bw[3][ct2] = j \n",
    "                ct2+=1\n",
    "    return torch.tensor(idxs_bw).to(torch.int32)\n",
    "            \n",
    "idxs_bw = make_idxs_backward2(idxs,sz).to(device)     \n",
    "            \n",
    "#idxs_bw = make_idxs_backward(idxs,sz).to(device)            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86c92398-3858-4630-8424-80f6225847ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 196608])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs_bw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37dcb82d-4627-4efd-9649-26e3e3fcdbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 196608]) torch.Size([196608])\n",
      "grad_X tensor([[ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        ...,\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409],\n",
      "        [ 0.8409,  2.2706, -0.2784,  ...,  0.2784, -2.2706, -0.8409]],\n",
      "       device='cuda:1')\n",
      "grad_weights tensor([-1044480., -1036288., -1028096.,  ...,  1028096.,  1036288.,\n",
      "         1044480.], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "import trisum_cuda\n",
    "variables = [X,idxs,idxs_bw,TriaSum.weights.data]\n",
    "print(variables[1].shape,variables[-1].shape,)\n",
    "grad_X, grad_weights = trisum_cuda.backward(external_grad.contiguous(), *variables)\n",
    "print(\"grad_X\", grad_X)\n",
    "print(\"grad_weights\", grad_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a611a27-d4c7-4e5f-aa6d-a3b1e966ba93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison to Autograd\n",
      "X grad tensor(0.0010, device='cuda:1')\n",
      "weights grad tensor(0., device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison to Autograd\")\n",
    "print(\"X grad\" ,torch.norm(grad_X-X.grad))\n",
    "print(\"weights grad\", torch.norm(grad_weights - TriaSum.weights.grad.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d576405-f5ce-4a30-8bd8-59ee73c83577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:1')\n"
     ]
    }
   ],
   "source": [
    "test = grad_weights - TriaSum.weights.grad.data\n",
    "print(test)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65828cd-7d18-4e7c-82c8-88bd146431ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5391a8a6-f2b4-43f8-a193-fcfc67272846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ccdf56c-e78c-4522-853a-c0445dce0493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66f1aa-9f69-48bf-823d-910e9cee121e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pre-defined gradcehk does ontt work well when indexing is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf5b03-2e21-4f48-9772-290267b247e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import gradcheck\n",
    "from trisumt import trisumFunction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abf0a1a-fe57-4c87-9afe-3a17b513a857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = torch.nn.Parameter(2.0*torch.ones( 3, 20)).double().to(device)\n",
    "#W = torch.nn.Parameter(torch.rand(20)).double().to(device)\n",
    "bs = 16\n",
    "sz = 20\n",
    "from torch.autograd import Variable\n",
    "X = Variable(torch.rand( bs, sz).double().to(device),requires_grad=True)\n",
    "W =  Variable(torch.rand(sz).double().to(device),requires_grad=True)\n",
    "idxs = torch.arange(sz).repeat(3*sz).reshape(1,3*sz**2).to(torch.int32).to(device)\n",
    "idxs =  Variable(torch.cat([idxs,torch.flip(idxs,[1])],dim = 0),requires_grad=False)\n",
    "variables = [X, W, idxs]\n",
    "\n",
    "gradcheck(trisumFunction.apply, variables) # eps=1e-6, atol=1e-4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e369a2d4-7d18-4fc0-97bd-1767e58752fc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478af839-f68e-4a7e-a173-62950a9fe866",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
